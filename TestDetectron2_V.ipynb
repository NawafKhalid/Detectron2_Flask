{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import sys\n",
    "import torch, torchvision\n",
    "# print(\"Torch version = \", torch.__version__)\n",
    "\n",
    "# print(\"TorchVision version = \", torchvision.__version__)\n",
    "# from torch.utils.collect_env import main\n",
    "# main()\n",
    "\n",
    "\n",
    "import detectron2\n",
    "# print(\"Detectron2 version = \", detectron2.__version__)\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple method to show the actual size of the image \n",
    "def display_image_in_actual_size(im_path):\n",
    "\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "    height, width, depth = im_data.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_in_actual_size(\"/home/nawaf/Downloads/I4K.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# You can download the model in your local machine and then use it without \"model_zoo.get_config_file\".\n",
    "# And only using \"cfg.merge_from_file(cfgfile)\".\n",
    "cfgfile = \"\"\n",
    "\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "# mask_rcnn_R_50_FPN_3x.yaml is 170MB\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# set threshold for this model\n",
    "# Threshold is basically when the model going to predict if the box/segmentation is true prediction\n",
    "# Ex. if the threshold is 0.5 the anything has IoU or AP (not sure with of these metrics going to use to use to predict) more than or equal 0.5\n",
    "# will concider as true prediction.  \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "# Tell it to use the CPU\n",
    "# cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is prediction time on GPU   0:00:01.129457\n"
     ]
    }
   ],
   "source": [
    "startT = datetime.now()\n",
    "\n",
    "# Predict input image\n",
    "outputs = predictor(im)\n",
    "\n",
    "endT = datetime.now()\n",
    "\n",
    "print(\"This is prediction time on GPU  \", endT - startT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances in the image = 1\n",
      "Predicted boxes:  [[1858.72509765625, 213.12550354003906, 3369.080078125, 2870.73974609375]]\n",
      "Scores of predicted classes:  [0.9900224804878235]\n",
      "Predicted classes: ['person']\n"
     ]
    }
   ],
   "source": [
    "# predict the number of instance in image.\n",
    "print(\"number of instances in the image =\", outputs[\"instances\"].pred_classes.numel()) \n",
    "# x0 = outputs[\"instances\"].pred_classes.numel()\n",
    "\n",
    "\n",
    "# # predict/show the boxes as tesor.\n",
    "# print(outputs[\"instances\"].pred_boxes) \n",
    "# x1 = outputs[\"instances\"].pred_boxes\n",
    "\n",
    "\n",
    "# predict/show the boxes as list.\n",
    "print(\"Predicted boxes: \", outputs[\"instances\"].get_fields()[\"pred_boxes\"].tensor.tolist()) \n",
    "# xx3 = outputs[\"instances\"].get_fields()[\"pred_boxes\"].tensor.tolist()\n",
    "\n",
    "\n",
    "# # predict/show the masks as tensor.\n",
    "# print(outputs[\"instances\"].pred_masks)\n",
    "# print(outputs[\"instances\"].pred_masks.tolist())\n",
    "# x3 = outputs[\"instances\"].pred_masks.tolist()\n",
    "# xx1 = outputs[\"instances\"].pred_masks\n",
    "\n",
    "\n",
    "# The predicted instances\n",
    "# print(outputs[\"instances\"].pred_classes)\n",
    "# x4 = outputs[\"instances\"].pred_classes\n",
    "\n",
    "\n",
    "# The predicted instances as list \n",
    "# print(outputs[\"instances\"].get_fields()[\"pred_classes\"].tolist())\n",
    "# x5 = outputs[\"instances\"].get_fields()[\"pred_classes\"].tolist()\n",
    "\n",
    "\n",
    "# The scores of predicted instances.\n",
    "print(\"Scores of predicted classes: \", outputs['instances'].get_fields()[\"scores\"].tolist())\n",
    "# x6 = outputs['instances'].get_fields()[\"scores\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# # We can't predict the keypoints, because we used mask_rcnn_R_50_FPN_3x. Please check model_zoo to find keypoints model. \n",
    "# # print(outputs[\"instances\"].pred_keypoints)\n",
    "\n",
    "Pred_classes = []\n",
    "\n",
    "# Go through the predicted class. \n",
    "for data in outputs[\"instances\"].pred_classes:\n",
    "    num = data.item() # The number of the instance \n",
    "    Pred_classes.append(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes[num])\n",
    "print(\"Predicted classes:\", Pred_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of predicted mask as a list =  80 bytes\n",
      "The size of predicted mask as a tensor =  80 bytes\n",
      "The size of predicted box as a list =  80 bytes\n",
      "The size of predicted class as a list =  80 bytes\n",
      "The size of scores of predicted classes as a list =  80 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of predicted mask as a list = \", sys.getsizeof(x3), \"bytes\")\n",
    "print(\"The size of predicted mask as a tensor = \", sys.getsizeof(xx1), \"bytes\")\n",
    "print(\"The size of predicted box as a list = \", sys.getsizeof(xx3), \"bytes\")\n",
    "print(\"The size of predicted class as a list = \", sys.getsizeof(x5), \"bytes\")\n",
    "print(\"The size of scores of predicted classes as a list = \", sys.getsizeof(x6), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "\n",
    "# Using 'draw_instance_predication' we can draw instance-level prediction and bounding box results on an image.\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# Draw the image with instance prediction\n",
    "plt.axis(\"off\")\n",
    "plt.figure(figsize=(100, 100))\n",
    "plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda9e9d65d4946742c59b9a1b187821df17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
